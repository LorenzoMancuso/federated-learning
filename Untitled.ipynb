{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@test {\"skip\": true}\n",
    "\n",
    "# NOTE: If you are running a Jupyter notebook, and installing a locally built\n",
    "# pip package, you may need to edit the following to point to the '.whl' file\n",
    "# on your local filesystem.\n",
    "\n",
    "# NOTE: The high-performance executor components used in this tutorial are not\n",
    "# yet included in the released pip package; you may need to compile from source.\n",
    "!pip install --quiet --upgrade tensorflow_federated\n",
    "!pip install --quiet --upgrade tf-nightly\n",
    "\n",
    "# NOTE: Jupyter requires a patch to asyncio.\n",
    "!pip install -q --upgrade nest_asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Hello, World!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import collections\n",
    "import warnings\n",
    "from six.moves import range\n",
    "import numpy as np\n",
    "import six\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "tf.compat.v1.enable_v2_behavior()\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# NOTE: If the statement below fails, it means that you are\n",
    "# using an older version of TFF without the high-performance\n",
    "# executor stack. Call `tff.framework.set_default_executor()`\n",
    "# instead to use the default reference runtime.\n",
    "if six.PY3:\n",
    "  tff.framework.set_default_executor(tff.framework.create_local_executor())\n",
    "\n",
    "tff.federated_computation(lambda: 'Hello, World!')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tff-datasets-public/fed_emnist_digitsonly.tar.bz2\n",
      "97402880/97398400 [==============================] - 13s 0us/step\n",
      "3383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  download and prepare the dataset\n",
    "\n",
    "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()\n",
    "print(len(emnist_train.client_ids))\n",
    "\n",
    "emnist_train.output_types, emnist_train.output_shapes\n",
    "\n",
    "# select only one example dataset and show one element's label\n",
    "example_dataset = emnist_train.create_tf_dataset_for_client(emnist_train.client_ids[0])\n",
    "example_element = iter(example_dataset).next()\n",
    "example_element['label'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OPTIONAL: show one example element\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(example_element['pixels'].numpy(), cmap='gray', aspect='equal')\n",
    "plt.grid('off')\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER PROCESS\n",
    "\n",
    "NUM_CLIENTS = 10\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 20\n",
    "SHUFFLE_BUFFER = 500\n",
    "\n",
    "# preprocess data transforming images into lists\n",
    "def preprocess(dataset):\n",
    "\n",
    "  def element_fn(element):\n",
    "    return collections.OrderedDict([\n",
    "        ('x', tf.reshape(element['pixels'], [-1])),\n",
    "        ('y', tf.reshape(element['label'], [1])),\n",
    "    ])\n",
    "\n",
    "  return dataset.repeat(NUM_EPOCHS).map(element_fn).shuffle(\n",
    "      SHUFFLE_BUFFER).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('x', array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "                     [1., 1., 1., ..., 1., 1., 1.],\n",
       "                     [1., 1., 1., ..., 1., 1., 1.],\n",
       "                     ...,\n",
       "                     [1., 1., 1., ..., 1., 1., 1.],\n",
       "                     [1., 1., 1., ..., 1., 1., 1.],\n",
       "                     [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)),\n",
       "             ('y', array([[3],\n",
       "                     [6],\n",
       "                     [6],\n",
       "                     [6],\n",
       "                     [5],\n",
       "                     [2],\n",
       "                     [5],\n",
       "                     [2],\n",
       "                     [1],\n",
       "                     [8],\n",
       "                     [8],\n",
       "                     [3],\n",
       "                     [0],\n",
       "                     [1],\n",
       "                     [0],\n",
       "                     [1],\n",
       "                     [7],\n",
       "                     [7],\n",
       "                     [0],\n",
       "                     [3]], dtype=int32))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show dataset structure, for learning purpose only\n",
    "preprocessed_example_dataset = preprocess(example_dataset)\n",
    "\n",
    "sample_batch = tf.nest.map_structure(lambda x: x.numpy(), iter(preprocessed_example_dataset).next())\n",
    "\n",
    "sample_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLIENT simulates federated data from clients\n",
    "def make_federated_data(client_data, client_ids):\n",
    "  return [preprocess(client_data.create_tf_dataset_for_client(x))\n",
    "          for x in client_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " <BatchDataset shapes: OrderedDict([(x, (None, 784)), (y, (None, 1))]), types: OrderedDict([(x, tf.float32), (y, tf.int32)])>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SERVER\n",
    "# Selects clients\n",
    "sample_clients = emnist_train.client_ids[0:NUM_CLIENTS]\n",
    "\n",
    "# select training data related to selected clients\n",
    "federated_train_data = make_federated_data(emnist_train, sample_clients)\n",
    "\n",
    "len(federated_train_data), federated_train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SERVER\n",
    "# Creates basic model for image classification with Keras\n",
    "def create_compiled_keras_model():\n",
    "  model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Dense(\n",
    "          10, activation=tf.nn.softmax, kernel_initializer='zeros', input_shape=(784,))])\n",
    "  \n",
    "  model.compile(\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      optimizer=tf.keras.optimizers.SGD(learning_rate=0.02),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform linear model into a federated learning model (different optimization function)\n",
    "def model_fn():\n",
    "  keras_model = create_compiled_keras_model()\n",
    "  return tff.learning.from_compiled_keras_model(keras_model, sample_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lore/anaconda3/envs/aaut/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# SERVER\n",
    "# Training the model over the collected federated data\n",
    "iterative_process = tff.learning.build_federated_averaging_process(model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'( -> <model=<trainable=<dense/kernel=float32[784,10],dense/bias=float32[10]>,non_trainable=<>>,optimizer_state=<int64>,delta_aggregate_state=<>,model_broadcast_state=<>>@SERVER)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(iterative_process.initialize.type_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's invoke the initialize computation to construct the server state.\n",
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  1, metrics=<sparse_categorical_accuracy=0.14979423582553864,loss=2.963947057723999>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The second of the pair of federated computations, next, represents a single round of Federated Averaging, \n",
    "which consists of pushing the server state (including the model parameters) to the clients, on-device training \n",
    "on their local data, collecting and averaging model updates, and producing a new updated model at the server.\n",
    "\n",
    "In particular, one should think about next() not as being a function that runs on a server, but rather being a \n",
    "declarative functional representation of the entire decentralized computation - some of the inputs are provided \n",
    "by the server (SERVER_STATE), but each participating device contributes its own local dataset.\n",
    "\"\"\"\n",
    "\n",
    "# SERVER_STATE, FEDERATED_DATA -> SERVER_STATE, TRAINING_METRICS\n",
    "# Single user example execution\n",
    "state, metrics = iterative_process.next(state, federated_train_data)\n",
    "print('round  1, metrics={}'.format(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  2, metrics=<sparse_categorical_accuracy=0.1885802447795868,loss=2.7068426609039307>\n",
      "round  3, metrics=<sparse_categorical_accuracy=0.22767490148544312,loss=2.5177485942840576>\n",
      "round  4, metrics=<sparse_categorical_accuracy=0.25823044776916504,loss=2.312215566635132>\n",
      "round  5, metrics=<sparse_categorical_accuracy=0.34156379103660583,loss=2.044433116912842>\n",
      "round  6, metrics=<sparse_categorical_accuracy=0.38240739703178406,loss=1.9038095474243164>\n",
      "round  7, metrics=<sparse_categorical_accuracy=0.4257201552391052,loss=1.7423803806304932>\n",
      "round  8, metrics=<sparse_categorical_accuracy=0.47242799401283264,loss=1.6325123310089111>\n",
      "round  9, metrics=<sparse_categorical_accuracy=0.5265432000160217,loss=1.4836434125900269>\n",
      "round 10, metrics=<sparse_categorical_accuracy=0.5660493969917297,loss=1.3954416513442993>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Let's run a few more rounds. As noted earlier, typically at this point you would pick a subset of your simulation \n",
    "data from a new randomly selected sample of users for each round in order to simulate a realistic deployment in which \n",
    "users continuously come and go\n",
    "\"\"\"\n",
    "\n",
    "for round_num in range(2, 11):\n",
    "  state, metrics = iterative_process.next(state, federated_train_data)\n",
    "  print('round {:2d}, metrics={}'.format(round_num, metrics))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
